{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0dd75dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the requests library, which allows us to send HTTP requests\n",
    "import requests\n",
    "\n",
    "# Import the BeautifulSoup class from the bs4 (Beautiful Soup) library\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Define the URL of the Wikipedia page we want to scrape\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_largest_companies_in_the_United_States_by_revenue'\n",
    "\n",
    "# Send an HTTP GET request to the specified URL and store the response in 'page'\n",
    "page = requests.get(url)\n",
    "\n",
    "# Create a BeautifulSoup object 'soup' by parsing the HTML content of the page\n",
    "soup = BeautifulSoup(page.text, 'html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef36ca50-2216-47ad-a258-5d6a6a4460c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all <table> elements in the parsed HTML content (soup object)\n",
    "tables = soup.find_all('table')\n",
    "\n",
    "# Select the second <table> element (index 1) from the list of tables\n",
    "table = tables[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "557c1a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all <th> elements (table headers) within the 'table' variable (which represents a specific <table> element)\n",
    "world_titles = table.find_all('th')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f5a2a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text content from each <th> element (table header) and remove leading/trailing whitespace\n",
    "world_table_titles = [title.text.strip() for title in world_titles]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3ef9f1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9c46070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a new DataFrame with specified column headers\n",
    "df = pd.DataFrame(columns=world_table_titles)\n",
    "\n",
    "# Iterate through each row of column_data starting from the second row\n",
    "for row in column_data[1:]:\n",
    "    # Extract all <td> elements (table cells) from the current row\n",
    "    row_data = row.find_all('td')\n",
    "    \n",
    "    # Extract text content from each <td> element and strip whitespace\n",
    "    individual_row_data = [data.text.strip() for data in row_data]\n",
    "    \n",
    "    # Determine the current length of the DataFrame\n",
    "    length = len(df)\n",
    "    \n",
    "    # Add a new row to the DataFrame using the extracted row data\n",
    "    df.loc[length] = individual_row_data\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head()\n",
    "\n",
    "# Save the DataFrame to a CSV file named 'largest_companies.csv' without indexing the rows\n",
    "df.to_csv('largest_companies.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c7aaa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
